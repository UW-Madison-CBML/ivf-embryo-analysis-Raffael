# Why 128×128 Instead of 526×526?

## Current Configuration: 128×128

### Reasons for 128×128:

1. **Computational Efficiency**
   - 128×128 = 16,384 pixels per frame
   - 526×526 = 276,676 pixels per frame (17× larger!)
   - With sequence length 20: 128×128 uses ~327K pixels per sample vs 5.5M for 526×526

2. **GPU Memory**
   - Current: ~16GB memory sufficient for batch_size=8
   - 526×526: Would need ~272GB memory for same batch size (impossible!)
   - Would need to reduce batch_size to 1-2, slowing training significantly

3. **Training Speed**
   - 128×128: ~15 min/epoch
   - 526×526: Estimated ~4-6 hours/epoch (16-24× slower)
   - Total training: 8-25 hours vs 200-300 hours

4. **Model Architecture**
   - Current encoder: 128→64→32→16 (3 pooling layers)
   - For 526: Would need 526→263→131→65→32→16 (5-6 pooling layers)
   - More layers = more parameters = slower training

5. **Sufficient for Task**
   - 128×128 is enough resolution for embryo development analysis
   - Most morphological features visible at this resolution
   - Higher resolution may not improve results significantly

## If You Want 526×526

### Required Changes:

1. **Update dataset_ivf.py**:
   ```python
   train_dataset = IVFSequenceDataset(index_csv, resize=526, norm="minmax01")
   ```

2. **Update model architecture** (model.py):
   - Add more pooling layers in encoder
   - Adjust decoder accordingly
   - Example: 526→263→131→65→32→16 (5 pooling layers)

3. **Reduce batch size**:
   ```python
   batch_size = 1  # or 2 at most
   ```

4. **Increase memory request**:
   ```
   request_memory = 64GB  # or more
   ```

5. **Expect much longer training**:
   - Per epoch: 4-6 hours
   - Total (50 epochs): 200-300 hours (8-12 days!)

## Recommendation

**Stick with 128×128** because:
- ✅ Fast training (12-15 hours total)
- ✅ Efficient GPU usage
- ✅ Sufficient resolution for analysis
- ✅ Can train multiple models/experiments

**Use 526×526 only if**:
- You have specific high-resolution features to capture
- You have weeks of GPU time available
- You've validated that 128×128 is insufficient

## Alternative: Progressive Training

Train at 128×128 first, then fine-tune at higher resolution if needed.

